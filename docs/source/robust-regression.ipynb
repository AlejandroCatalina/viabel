{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stan Models: A Robust Linear Regression Example\n",
    "\n",
    "We will approximate the posterior for the simple 2D robust linear regression model\n",
    "\n",
    "$$\\beta_i \\sim \\mathcal{N}(0, 10)$$\n",
    "$$y_n | x_n, \\beta, \\sigma \\sim \\mathcal{T}_{40}(\\beta^\\top x_n, 1)$$\n",
    "\n",
    "and use Stan to compute (the gradient of) the model log density. \n",
    "\n",
    "For more details and discussion of this example, see:\n",
    "\n",
    "[Practical posterior error bounds from variational objectives](https://arxiv.org/abs/1910.04102).\n",
    "Jonathan H. Huggins,\n",
    "Miko&#0322;aj Kasprzak,\n",
    "Trevor Campbell,\n",
    "Tamara Broderick.\n",
    "In *Proc. of the 23rd International Conference on Artificial Intelligence and\n",
    "Statistics* (AISTATS), Palermo, Italy. PMLR: Volume 108, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import autograd.numpy as np\n",
    "import pystan\n",
    "\n",
    "from viabel import bbvi, vi_diagnostics, MultivariateT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for comparing to ground-truth posterior\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'lines.linewidth': 2})\n",
    "\n",
    "def plot_approx_and_exact_contours(log_density, approx, var_param, cmap2='Reds'):\n",
    "    xlim = [-4,-1]\n",
    "    ylim = [-.5,3.5]\n",
    "    xlist = np.linspace(*xlim, 100)\n",
    "    ylist = np.linspace(*ylim, 100)\n",
    "    X, Y = np.meshgrid(xlist, ylist)\n",
    "    XY = np.concatenate([np.atleast_2d(X.ravel()), np.atleast_2d(Y.ravel())]).T\n",
    "    zs = np.exp(log_density(XY))\n",
    "    Z = zs.reshape(X.shape)\n",
    "    zsapprox = np.exp(approx.log_density(var_param, XY))\n",
    "    Zapprox = zsapprox.reshape(X.shape)\n",
    "    cs_post = plt.contour(X, Y, Z, cmap='Greys', linestyles='solid')\n",
    "    cs_post.collections[len(cs_post.collections)//2].set_label('Posterior')\n",
    "    cs_approx = plt.contour(X, Y, Zapprox, cmap=cmap2, linestyles='solid')\n",
    "    cs_approx.collections[len(cs_approx.collections)//2].set_label('Approximation')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def check_accuracy(true_mean, true_cov, var_param, approx):\n",
    "    approx_mean, approx_cov = approx.mean_and_cov(var_param)\n",
    "    true_std = np.sqrt(np.diag(true_cov))\n",
    "    approx_std = np.sqrt(np.diag(approx_cov))\n",
    "    mean_error=np.linalg.norm(true_mean - approx_mean)\n",
    "    cov_error_2=np.linalg.norm(true_cov - approx_cov, ord=2)\n",
    "    cov_norm_2=np.linalg.norm(true_cov, ord=2)\n",
    "    std_error=np.linalg.norm(true_std - approx_std)\n",
    "    \n",
    "    print('mean error             = {:.3g}'.format(mean_error))\n",
    "    print('stdev error            = {:.3g}'.format(std_error))\n",
    "    print('||cov error||_2^{{1/2}}  = {:.3g}'.format(np.sqrt(cov_error_2)))\n",
    "    print('||true cov||_2^{{1/2}}   = {:.3g}'.format(np.sqrt(cov_norm_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compile the robust regression Stan model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model_file = 'robust_reg_model.pkl'\n",
    "try:\n",
    "    with open(compiled_model_file, 'rb') as f:\n",
    "        regression_model = pickle.load(f)\n",
    "except:\n",
    "    regression_model = pystan.StanModel(file='robust_regression.stan', \n",
    "                                        model_name='robust_regression')\n",
    "with open(compiled_model_file, 'wb') as f:\n",
    "    pickle.dump(regression_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to as use a data, generate 25 observations from the model with $\\beta = (-2, 1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5039)\n",
    "beta_gen = np.array([-2, 1])\n",
    "N = 25\n",
    "x = np.random.randn(N, 2).dot(np.array([[1,.75],[.75, 1]]))\n",
    "y_raw = x.dot(beta_gen) + np.random.standard_t(40, N)\n",
    "y = y_raw - np.mean(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purposes, generate ground-truth posterior samples using Stan's dynamic HMC implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N=N, x=x, y=y, df=40)\n",
    "fit = regression_model.sampling(data=data, iter=50000, thin=50, chains=4)\n",
    "true_mean = np.mean(fit['beta'], axis=0)\n",
    "true_cov = np.cov(fit['beta'].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard mean-field variational inference\n",
    "\n",
    "As a first example, we compute a mean field variational approximation using standard variational inference -- that is, by maximimizing the evidence lower bound (ELBO):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_results = bbvi(2, fit=fit, num_mc_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check approximation quality using `vi_diagnostics`, which determines the approximation is not good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_objective = mf_results['objective']\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    diagnostics = vi_diagnostics(mf_results['var_param'], objective=mf_objective, \n",
    "                                 n_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, due to the strong posterior correlation, the variational approximation dramatically underestimates uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_approx_and_exact_contours(mf_objective.model, mf_objective.approx, \n",
    "                               mf_results['var_param'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm the poor approximation quality numerically by examining the mean, standard deviation, and covariance errors as compared to the ground-truth estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(true_mean, true_cov, mf_results['var_param'], mf_objective.approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An approximation with full covariance\n",
    "\n",
    "To get a good approximation, we can instead use a Multivariate *t* variational family with a full-rank scaling matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_results = bbvi(2, n_iters=2500, fit=fit, approx=MultivariateT(2, 100), num_mc_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagnostics suggest the approximation is accurate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_objective = t_results['objective']\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    diagnostics = vi_diagnostics(t_results['var_param'], objective=t_objective, \n",
    "                                 n_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection and numerical checks confirm the diagnostics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_approx_and_exact_contours(t_objective.model, t_objective.approx, t_results['var_param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(true_mean, true_cov, t_results['var_param'], t_objective.approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
